{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "from mnist import MNIST\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "mndata = MNIST('../HW1/Dataset')\n",
    "trainX = np.array(mndata.load_training()[0])[:50000]\n",
    "trainY = np.array(mndata.load_training()[1])[:50000]\n",
    "\n",
    "testX = np.array(mndata.load_testing()[0])[:1000]\n",
    "testY = np.array(mndata.load_testing()[1])[:1000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "valIndices = np.random.choice(len(trainX), 2000)\n",
    "nonValIndices = [x for x in range(len(trainX)) if x not in valIndices]\n",
    "\n",
    "valX = trainX[valIndices]\n",
    "valY = trainY[valIndices]\n",
    "\n",
    "trainX = trainX[nonValIndices]\n",
    "trainY = trainY[nonValIndices]\n",
    "\n",
    "testX = np.array(mndata.load_testing()[0])[:2000]\n",
    "testY = np.array(mndata.load_testing()[1])[:2000]\n",
    "\n",
    "def feat(data,i):\n",
    "    return data[i].tolist()\n",
    "\n",
    "def oneHot(clas, noOfClasses):\n",
    "    feat = np.zeros(noOfClasses)\n",
    "    feat[clas] = 1;\n",
    "    return feat\n",
    "\n",
    "trnX = np.array([feat(trainX,i) for i in range(trainX.shape[0])])/256.0\n",
    "trnY = np.array([oneHot(trainY[i], 10) for i in range(trainX.shape[0])])\n",
    "\n",
    "tstX = np.array([feat(testX,i) for i in range(testX.shape[0])])/256.0\n",
    "tstY = np.array([oneHot(testY[i], 10) for i in range(testX.shape[0])])\n",
    "\n",
    "valX = np.array([feat(valX,i) for i in range(valX.shape[0])])/256.0\n",
    "valY = np.array([oneHot(valY[i], 10) for i in range(valX.shape[0])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.,  0.,  0.,  0.,  0.,  1.,  0.,  0.,  0.,  0.],\n",
       "       [ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0.,  0.,  1.,  0.,  0.,  0.,  0.,  0.],\n",
       "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  1.],\n",
       "       [ 0.,  0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0.,  0.,  1.,  0.,  0.,  0.,  0.,  0.]])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trnY[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8.8\n",
      "12.0\n",
      "12.8\n",
      "15.1\n",
      "15.35\n",
      "18.2\n",
      "18.95\n",
      "21.35\n",
      "22.8\n",
      "25.35\n",
      "26.85\n",
      "28.95\n",
      "30.75\n",
      "32.9\n",
      "34.35\n",
      "35.6\n",
      "37.65\n",
      "39.05\n",
      "40.8\n",
      "41.85\n",
      "43.0\n",
      "43.85\n",
      "44.5\n",
      "45.8\n",
      "46.7\n",
      "47.6\n",
      "48.25\n",
      "48.9\n",
      "49.55\n",
      "50.8\n",
      "52.1\n",
      "53.0\n",
      "53.75\n",
      "54.7\n",
      "55.3\n",
      "56.15\n",
      "56.9\n",
      "57.85\n",
      "58.4\n",
      "59.0\n",
      "59.5\n",
      "60.2\n",
      "60.95\n",
      "61.75\n",
      "62.05\n",
      "62.55\n",
      "63.1\n",
      "63.55\n",
      "63.95\n",
      "64.1\n",
      "64.25\n",
      "64.6\n",
      "65.1\n",
      "65.45\n",
      "65.7\n",
      "65.9\n",
      "66.3\n",
      "66.8\n",
      "67.1\n",
      "67.25\n",
      "67.5\n",
      "67.75\n",
      "67.95\n",
      "68.1\n",
      "68.25\n",
      "68.5\n",
      "68.8\n",
      "69.1\n",
      "69.25\n",
      "69.5\n",
      "69.6\n",
      "69.9\n",
      "70.15\n",
      "70.4\n",
      "70.75\n",
      "70.9\n",
      "71.25\n",
      "71.3\n",
      "71.6\n",
      "71.8\n",
      "72.15\n",
      "72.35\n",
      "72.4\n",
      "72.65\n",
      "72.65\n",
      "72.7\n",
      "72.9\n",
      "73.05\n",
      "73.05\n",
      "73.1\n",
      "73.1\n",
      "73.35\n",
      "73.45\n",
      "73.6\n",
      "73.65\n",
      "73.6\n",
      "73.75\n",
      "73.8\n",
      "73.95\n",
      "74.0\n"
     ]
    }
   ],
   "source": [
    "def sigmoid(x):\n",
    "    return 1.0/(1+np.exp(-1*np.array(x)))\n",
    "\n",
    "def grad(x):\n",
    "    return x*(1-x)\n",
    "\n",
    "def softmax(x):\n",
    "    x = np.exp(x)\n",
    "    x = x/x.sum(axis=1)[:, None]\n",
    "    return x\n",
    "    \n",
    "maxValAcc = 0\n",
    "testAcc = 0\n",
    "lr = 0.00001\n",
    "\n",
    "# randomly initialize our weights with mean 0\n",
    "n_hid_1 = 50\n",
    "n_hid_2 = 80\n",
    "W1 = 2*np.random.random((784,n_hid_1)) - 1\n",
    "bias1 = 2*np.random.random((n_hid_1)) - 1\n",
    "W2 = 2*np.random.random((n_hid_1,n_hid_2)) - 1\n",
    "bias2 = 2*np.random.random((n_hid_2)) - 1\n",
    "W3 = 2*np.random.random((n_hid_2,10)) - 1\n",
    "bias3 = 2*np.random.random((10)) - 1\n",
    "\n",
    "for j in xrange(100):\n",
    "    A1 = np.dot(trnX, W1) + bias1\n",
    "    l1 = sigmoid(A1)\n",
    "    \n",
    "    A2 = np.dot(l1, W2) + bias2\n",
    "    l2 = sigmoid(A2)\n",
    "    \n",
    "    A3 = np.dot(l2, W3) + bias3\n",
    "    l3 = softmax(A3)\n",
    "\n",
    "    # Errors in output layer\n",
    "    d3 = (l3 - trnY)\n",
    "    dbias3 = np.sum(d3, axis = 0)\n",
    "        \n",
    "    # Delta of W3\n",
    "    dW3 = np.dot(l2.T, d3)\n",
    "\n",
    "    # Errors in 2nd hidden layer\n",
    "    d2 = np.dot(d3, W3.T)*grad(l2)\n",
    "    dbias2 = np.sum(d2, axis = 0)    \n",
    "    \n",
    "    # Delta W2\n",
    "    dW2 = np.dot(l1.T, d2)\n",
    "    \n",
    "    # Errors in 2nd hidden layer\n",
    "    d1 = np.dot(d2, W2.T)*grad(l1)\n",
    "    dbias1 = np.sum(d1, axis = 0)    \n",
    "    \n",
    "    # Delta W3\n",
    "    dW1 = np.dot(trnX.T, d1)\n",
    "    \n",
    "    W3 -= lr*dW3\n",
    "    bias3 -= lr*dbias3\n",
    "    W2 -= lr*dW2\n",
    "    bias2 -= lr*dbias2\n",
    "    W1 -= lr*dW1\n",
    "    bias1 -= lr*dbias1\n",
    "    \n",
    "    prediction = softmax(np.dot(sigmoid(np.dot(sigmoid(np.dot(valX, W1)+bias1), W2)+bias2), W3)+bias3)\n",
    "    correct = [1 if a == b else 0 for (a, b) in zip(np.argmax(valY, axis = 1), np.argmax(prediction, axis = 1))]\n",
    "    valAcc = np.sum(correct)*100.0/len(valX)\n",
    "    if(valAcc > maxValAcc):\n",
    "        prediction = softmax(np.dot(sigmoid(np.dot(sigmoid(np.dot(tstX, W1)+bias1), W2)+bias2), W3)+bias3)\n",
    "        correct = [1 if a == b else 0 for (a, b) in zip(np.argmax(tstY, axis = 1), np.argmax(prediction, axis = 1))]\n",
    "        testAcc = np.sum(correct)*100.0/len(tstX)\n",
    "        print testAcc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
