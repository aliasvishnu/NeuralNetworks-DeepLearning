{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "from mnist import MNIST\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "mndata = MNIST('../HW1/Dataset')\n",
    "trainX = np.array(mndata.load_training()[0])[:50000]\n",
    "trainY = np.array(mndata.load_training()[1])[:50000]\n",
    "\n",
    "testX = np.array(mndata.load_testing()[0])[:1000]\n",
    "testY = np.array(mndata.load_testing()[1])[:1000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "valIndices = np.random.choice(len(trainX), 2000)\n",
    "nonValIndices = [x for x in range(len(trainX)) if x not in valIndices]\n",
    "\n",
    "valX = trainX[valIndices]\n",
    "valY = trainY[valIndices]\n",
    "\n",
    "trainX = trainX[nonValIndices]\n",
    "trainY = trainY[nonValIndices]\n",
    "\n",
    "testX = np.array(mndata.load_testing()[0])[:2000]\n",
    "testY = np.array(mndata.load_testing()[1])[:2000]\n",
    "\n",
    "def feat(data,i):\n",
    "    return data[i].tolist()\n",
    "\n",
    "def oneHot(clas, noOfClasses):\n",
    "    feat = np.zeros(noOfClasses)\n",
    "    feat[clas] = 1;\n",
    "    return feat\n",
    "\n",
    "trnX = np.array([feat(trainX,i) for i in range(trainX.shape[0])])/256.0\n",
    "trnY = np.array([oneHot(trainY[i], 10) for i in range(trainX.shape[0])])\n",
    "\n",
    "tstX = np.array([feat(testX,i) for i in range(testX.shape[0])])/256.0\n",
    "tstY = np.array([oneHot(testY[i], 10) for i in range(testX.shape[0])])\n",
    "\n",
    "valX = np.array([feat(valX,i) for i in range(valX.shape[0])])/256.0\n",
    "valY = np.array([oneHot(valY[i], 10) for i in range(valX.shape[0])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def sigmoid(x):\n",
    "    return 1.0/(1+np.exp(-1*np.array(x)))\n",
    "\n",
    "def lecun(x):\n",
    "    return 1.7159*np.tanh(2.0*x/3)\n",
    "\n",
    "def gradSigmoid(x):\n",
    "    return x*(1-x)\n",
    "\n",
    "def gradLecun(x):\n",
    "    t = 2.0*x/3\n",
    "    return 1.7159*(1-t**2)\n",
    "\n",
    "def softmax(x):\n",
    "    x = np.exp(x)\n",
    "    x = x/x.sum(axis=1)[:, None]\n",
    "    return x\n",
    "    \n",
    "maxValAcc = 0\n",
    "testAcc = 0\n",
    "lr = 0.00001\n",
    "mom = 0.8\n",
    "\n",
    "trnAcc = []\n",
    "valAcc = []\n",
    "tstAcc = []\n",
    "\n",
    "# randomly initialize our weights with mean 0\n",
    "n_hid_1 = 80\n",
    "n_hid_2 = 140\n",
    "W1 = 2*np.random.random((784,n_hid_1)) - 1\n",
    "bias1 = 2*np.random.random((n_hid_1)) - 1\n",
    "W2 = 2*np.random.random((n_hid_1,n_hid_2)) - 1\n",
    "bias2 = 2*np.random.random((n_hid_2)) - 1\n",
    "W3 = 2*np.random.random((n_hid_2,10)) - 1\n",
    "bias3 = 2*np.random.random((10)) - 1\n",
    "\n",
    "prevW1=0\n",
    "prevW2=0\n",
    "prevW3=0\n",
    "prevB1=0\n",
    "prevB2=0\n",
    "prevB3=0\n",
    "\n",
    "for j in xrange(100):\n",
    "    A1 = np.dot(trnX, W1+mom*prevW1) + bias1 + mom*prevB1\n",
    "    l1 = sigmoid(A1)\n",
    "    \n",
    "    A2 = np.dot(l1, W2+mom*prevW2) + bias2 + mom*prevB2\n",
    "    l2 = sigmoid(A2)\n",
    "    \n",
    "    A3 = np.dot(l2, W3+mom*prevW3) + bias3 + mom*prevB3\n",
    "    l3 = softmax(A3)\n",
    "\n",
    "    # Errors in output layer\n",
    "    d3 = (l3 - trnY)\n",
    "    dbias3 = np.sum(d3, axis = 0)\n",
    "        \n",
    "    # Delta of W3\n",
    "    dW3 = np.dot(l2.T, d3)\n",
    "\n",
    "    # Errors in 2nd hidden layer\n",
    "    d2 = np.dot(d3, (W3+mom*prevW3).T)*gradSigmoid(l2)\n",
    "    dbias2 = np.sum(d2, axis = 0)    \n",
    "    \n",
    "    # Delta W2\n",
    "    dW2 = np.dot(l1.T, d2)\n",
    "    \n",
    "    # Errors in 2nd hidden layer\n",
    "    d1 = np.dot(d2, (W2+mom*prevW2).T)*gradSigmoid(l1)\n",
    "    dbias1 = np.sum(d1, axis = 0)    \n",
    "    \n",
    "    # Delta W1\n",
    "    dW1 = np.dot(trnX.T, d1)\n",
    "    \n",
    "    currW3=mom*prevW3-lr*dW3\n",
    "    currB3=mom*prevB3-lr*dbias3\n",
    "    currW2=mom*prevW2-lr*dW2\n",
    "    currB2=mom*prevB2-lr*dbias2\n",
    "    currW1=mom*prevW1-lr*dW1\n",
    "    currB1=mom*prevB1-lr*dbias1\n",
    "    \n",
    "    prevW3=currW3\n",
    "    prevW2=currW2\n",
    "    prevW1=currW1\n",
    "    prevW3=currB3\n",
    "    prevB2=currB2\n",
    "    prevB1=currB1\n",
    "    \n",
    "    W3 +=currW3\n",
    "    bias3 +=currB3\n",
    "    W2 +=currW2\n",
    "    bias2 +=currB2\n",
    "    W1 +=currW1\n",
    "    bias1 +=currB1\n",
    "    \n",
    "    prediction = softmax(np.dot(sigmoid(np.dot(sigmoid(np.dot(valX, W1)+bias1), W2)+bias2), W3)+bias3)\n",
    "    correct = [1 if a == b else 0 for (a, b) in zip(np.argmax(valY, axis = 1), np.argmax(prediction, axis = 1))]\n",
    "    valAcc.append(np.sum(correct)*100.0/len(valX))\n",
    "    \n",
    "    prediction = softmax(np.dot(sigmoid(np.dot(sigmoid(np.dot(trnX, W1)+bias1), W2)+bias2), W3)+bias3)\n",
    "    correct = [1 if a == b else 0 for (a, b) in zip(np.argmax(trnY, axis = 1), np.argmax(prediction, axis = 1))]\n",
    "    trnAcc.append(np.sum(correct)*100.0/len(trnX))   \n",
    "    \n",
    "    prediction = softmax(np.dot(sigmoid(np.dot(sigmoid(np.dot(tstX, W1)+bias1), W2)+bias2), W3)+bias3)\n",
    "    correct = [1 if a == b else 0 for (a, b) in zip(np.argmax(tstY, axis = 1), np.argmax(prediction, axis = 1))]\n",
    "    tstAcc.append(np.sum(correct)*100.0/len(tstX))   \n",
    "    \n",
    "    if(valAcc[-1] > maxValAcc):\n",
    "        maxValAcc = valAcc[-1]\n",
    "        maxTestAcc = tstAcc[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.plot([x+1 for x in range(len(trnAcc))], trnAcc, label = 'Training Accuracy')\n",
    "plt.plot([x+1 for x in range(len(valAcc))], valAcc, label = 'Validation Accuracy')\n",
    "plt.plot([x+1 for x in range(len(tstAcc))], tstAcc, label = 'Testing Accuracy')\n",
    "plt.xlabel(\"Iterations\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.legend(loc='lower right', shadow=True)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
