{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "from mnist import MNIST\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "mndata = MNIST('../HW1/Dataset')\n",
    "trainX = np.array(mndata.load_training()[0])[:50000]\n",
    "trainY = np.array(mndata.load_training()[1])[:50000]\n",
    "\n",
    "testX = np.array(mndata.load_testing()[0])[:1000]\n",
    "testY = np.array(mndata.load_testing()[1])[:1000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "valIndices = np.random.choice(len(trainX), 2000)\n",
    "nonValIndices = [x for x in range(len(trainX)) if x not in valIndices]\n",
    "\n",
    "valX = trainX[valIndices]\n",
    "valY = trainY[valIndices]\n",
    "\n",
    "trainX = trainX[nonValIndices]\n",
    "trainY = trainY[nonValIndices]\n",
    "\n",
    "testX = np.array(mndata.load_testing()[0])[:2000]\n",
    "testY = np.array(mndata.load_testing()[1])[:2000]\n",
    "\n",
    "def feat(data,i):\n",
    "    return data[i].tolist()\n",
    "\n",
    "def oneHot(clas, noOfClasses):\n",
    "    feat = np.zeros(noOfClasses)\n",
    "    feat[clas] = 1;\n",
    "    return feat\n",
    "\n",
    "trnX = np.array([feat(trainX,i) for i in range(trainX.shape[0])])/256.0\n",
    "trnY = np.array([oneHot(trainY[i], 10) for i in range(trainX.shape[0])])\n",
    "\n",
    "tstX = np.array([feat(testX,i) for i in range(testX.shape[0])])/256.0\n",
    "tstY = np.array([oneHot(testY[i], 10) for i in range(testX.shape[0])])\n",
    "\n",
    "valX = np.array([feat(valX,i) for i in range(valX.shape[0])])/256.0\n",
    "valY = np.array([oneHot(valY[i], 10) for i in range(valX.shape[0])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.,  0.,  0.,  0.,  0.,  1.,  0.,  0.,  0.,  0.],\n",
       "       [ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0.,  0.,  1.,  0.,  0.,  0.,  0.,  0.],\n",
       "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  1.],\n",
       "       [ 0.,  0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0.,  0.,  1.,  0.,  0.,  0.,  0.,  0.]])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trnY[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14.75\n",
      "13.4\n",
      "15.45\n",
      "10.95\n",
      "9.9\n",
      "20.55\n",
      "21.3\n",
      "25.85\n",
      "29.9\n",
      "36.4\n",
      "37.6\n",
      "39.5\n",
      "34.35\n",
      "30.4\n",
      "14.95\n",
      "29.6\n",
      "48.25\n",
      "49.45\n",
      "51.4\n",
      "51.0\n",
      "47.55\n",
      "43.0\n",
      "48.1\n",
      "57.1\n",
      "62.2\n",
      "63.15\n",
      "61.4\n",
      "58.6\n",
      "54.1\n",
      "60.1\n",
      "62.3\n",
      "71.1\n",
      "69.65\n",
      "72.8\n",
      "71.35\n",
      "73.1\n",
      "70.0\n",
      "67.1\n",
      "59.0\n",
      "53.3\n",
      "57.45\n",
      "61.3\n",
      "68.15\n",
      "67.65\n",
      "68.4\n",
      "69.15\n",
      "68.85\n",
      "71.4\n",
      "69.3\n",
      "72.65\n",
      "71.15\n",
      "74.25\n",
      "72.5\n",
      "75.1\n",
      "73.45\n",
      "76.15\n",
      "74.25\n",
      "77.0\n",
      "75.25\n",
      "77.5\n",
      "75.8\n",
      "78.3\n",
      "76.65\n",
      "78.75\n",
      "77.55\n",
      "79.1\n",
      "78.05\n",
      "79.85\n",
      "79.15\n",
      "79.95\n",
      "79.65\n",
      "80.6\n",
      "80.15\n",
      "81.5\n",
      "80.85\n",
      "81.8\n",
      "82.05\n",
      "82.4\n",
      "82.5\n",
      "82.9\n",
      "82.85\n",
      "82.9\n",
      "83.65\n",
      "83.3\n",
      "84.05\n",
      "83.55\n",
      "84.4\n",
      "83.65\n",
      "84.75\n",
      "83.65\n",
      "84.95\n",
      "83.85\n",
      "84.95\n",
      "84.1\n",
      "85.1\n",
      "84.1\n",
      "85.35\n",
      "84.15\n",
      "85.45\n",
      "84.25\n"
     ]
    }
   ],
   "source": [
    "def sigmoid(x):\n",
    "    return 1.0/(1+np.exp(-1*np.array(x)))\n",
    "\n",
    "def grad(x):\n",
    "    return x*(1-x)\n",
    "\n",
    "def softmax(x):\n",
    "    x = np.exp(x)\n",
    "    x = x/x.sum(axis=1)[:, None]\n",
    "    return x\n",
    "    \n",
    "maxValAcc = 0\n",
    "testAcc = 0\n",
    "lr = 0.0001\n",
    "\n",
    "# randomly initialize our weights with mean 0\n",
    "n_hid_1 = 50\n",
    "n_hid_2 = 80\n",
    "W1 = 2*np.random.random((784,n_hid_1)) - 1\n",
    "bias1 = 2*np.random.random((n_hid_1)) - 1\n",
    "W2 = 2*np.random.random((n_hid_1,n_hid_2)) - 1\n",
    "bias2 = 2*np.random.random((n_hid_2)) - 1\n",
    "W3 = 2*np.random.random((n_hid_2,10)) - 1\n",
    "bias3 = 2*np.random.random((10)) - 1\n",
    "\n",
    "for j in xrange(100):\n",
    "    A1 = np.dot(trnX, W1) + bias1\n",
    "    l1 = sigmoid(A1)\n",
    "    \n",
    "    A2 = np.dot(l1, W2) + bias2\n",
    "    l2 = sigmoid(A2)\n",
    "    \n",
    "    A3 = np.dot(l2, W3) + bias3\n",
    "    l3 = softmax(A3)\n",
    "\n",
    "    # Errors in output layer\n",
    "    d3 = (l3 - trnY)\n",
    "    dbias3 = np.sum(d3, axis = 0)\n",
    "        \n",
    "    # Delta of W3\n",
    "    dW3 = np.dot(l2.T, d3)\n",
    "\n",
    "    # Errors in 2nd hidden layer\n",
    "    d2 = np.dot(d3, W3.T)*grad(l2)\n",
    "    dbias2 = np.sum(d2, axis = 0)    \n",
    "    \n",
    "    # Delta W2\n",
    "    dW2 = np.dot(l1.T, d2)\n",
    "    \n",
    "    # Errors in 2nd hidden layer\n",
    "    d1 = np.dot(d2, W2.T)*grad(l1)\n",
    "    dbias1 = np.sum(d1, axis = 0)    \n",
    "    \n",
    "    # Delta W3\n",
    "    dW1 = np.dot(trnX.T, d1)\n",
    "    \n",
    "    W3 -= lr*dW3\n",
    "    bias3 -= lr*dbias3\n",
    "    W2 -= lr*dW2\n",
    "    bias2 -= lr*dbias2\n",
    "    W1 -= lr*dW1\n",
    "    bias1 -= lr*dbias1\n",
    "    \n",
    "    prediction = softmax(np.dot(sigmoid(np.dot(sigmoid(np.dot(valX, W1)+bias1), W2)+bias2), W3)+bias3)\n",
    "    correct = [1 if a == b else 0 for (a, b) in zip(np.argmax(valY, axis = 1), np.argmax(prediction, axis = 1))]\n",
    "    valAcc = np.sum(correct)*100.0/len(valX)\n",
    "    if(valAcc > maxValAcc):\n",
    "        prediction = softmax(np.dot(sigmoid(np.dot(sigmoid(np.dot(tstX, W1)+bias1), W2)+bias2), W3)+bias3)\n",
    "        correct = [1 if a == b else 0 for (a, b) in zip(np.argmax(tstY, axis = 1), np.argmax(prediction, axis = 1))]\n",
    "        testAcc = np.sum(correct)*100.0/len(tstX)\n",
    "        print testAcc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
