{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "from mnist import MNIST\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "mndata = MNIST('Dataset')\n",
    "trainX = np.array(mndata.load_training()[0])[:20000]\n",
    "trainY = np.array(mndata.load_training()[1])[:20000]\n",
    "\n",
    "#random selection of data for training and validation\n",
    "valIndices = np.random.choice(len(trainX), 2000)\n",
    "nonValIndices = [x for x in range(len(trainX)) if x not in valIndices]\n",
    "\n",
    "valX = trainX[valIndices]\n",
    "valY = trainY[valIndices]\n",
    "\n",
    "trainX = trainX[nonValIndices]\n",
    "trainY = trainY[nonValIndices]\n",
    "\n",
    "testX = np.array(mndata.load_testing()[0])[:2000]\n",
    "testY = np.array(mndata.load_testing()[1])[:2000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def feat(data,i):\n",
    "    return [1] + data[i].tolist()\n",
    "\n",
    "def oneHot(clas, noOfClasses):\n",
    "    feat = np.zeros(noOfClasses)\n",
    "    feat[clas] = 1;\n",
    "    return feat\n",
    "\n",
    "trnX = np.array([feat(trainX,i) for i in range(trainX.shape[0])])/256.0\n",
    "trnY = np.array([oneHot(trainY[i], 10) for i in range(trainX.shape[0])])\n",
    "\n",
    "tstX = np.array([feat(testX,i) for i in range(testX.shape[0])])/256.0\n",
    "tstY = np.array([oneHot(testY[i], 10) for i in range(testX.shape[0])])\n",
    "\n",
    "valX = np.array([feat(valX,i) for i in range(valX.shape[0])])/256.0\n",
    "valY = np.array([oneHot(valY[i], 10) for i in range(valX.shape[0])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def softmax(x):\n",
    "    x = np.exp(x)\n",
    "    x = x/x.sum(axis=1)[:, None]\n",
    "    return x\n",
    "\n",
    "def error(trnY, y, lamda):\n",
    "    err = 0    \n",
    "    for i in range(len(trnY)):\n",
    "        for k in range(10):\n",
    "            if(y[i, k] < 0.00001):\n",
    "                y[i, k] = 0.00001\n",
    "            elif(y[i, k] > 0.99999):\n",
    "                y[i, k] = 0.99999\n",
    "            err += trnY[i, k]*np.log(y[i, k])\n",
    "    err=-1*err/len(trnY)\n",
    "    # L2 regularization\n",
    "    err += lamda * np.linalg.norm(w)**2\n",
    "    # L1 regularization\n",
    "#     err += lamda * np.sum(np.abs(w))\n",
    "    return err\n",
    "\n",
    "def accuracy(y, y_):\n",
    "    y_ = np.argmax(y_, axis = 1)\n",
    "    y = np.argmax(y, axis = 1)\n",
    "    count = 0\n",
    "    for i in range(len(y_)):\n",
    "        if y_[i] == y[i]:\n",
    "            count += 1\n",
    "    return count*100.0/len(y_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "err = [[], [], []]\n",
    "acc = [[], [], []]\n",
    "\n",
    "lr = 0.0001\n",
    "w = (np.random.rand(10, 785)-0.5)\n",
    "w_past = np.zeros((4, 10, 785))\n",
    "count = 0\n",
    "past_loss = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "lamda = [0.01,0.001, 0.0001, 0.00001]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# for i in range(10):\n",
    "#     print i\n",
    "#     y = softmax(np.dot(trnX,np.transpose(w)))\n",
    "#     loss = error(trnY, y)\n",
    "#     print \"Loss is \", loss\n",
    "#     err[0].append(loss)\n",
    "#     err[1].append(error(tstY, softmax(np.dot(tstX,np.transpose(w)))))\n",
    "#     err[2].append(error(valY, softmax(np.dot(valX,np.transpose(w)))))\n",
    "#     acc[0].append(accuracy(trnY, y))\n",
    "#     acc[1].append(accuracy(tstY, softmax(np.dot(tstX,np.transpose(w)))))\n",
    "#     acc[2].append(accuracy(valY, softmax(np.dot(valX,np.transpose(w)))))\n",
    "#     if past_loss <= loss and i > 100:\n",
    "#         count += 1\n",
    "#         w_past[0] = w_past[1]\n",
    "#         w_past[1] = w_past[2]\n",
    "#         w_past[2] = w_past[3]\n",
    "#         w_past[3] = w\n",
    "#     elif past_loss > loss:\n",
    "#         count = 0\n",
    "#         past_loss = -1\n",
    "#     if count > 3:\n",
    "#         break\n",
    "#     grad = np.dot(np.transpose(trnY-y), trnX)\n",
    "#     w = w + lr*grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "max_acc = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "Here\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "Here\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n"
     ]
    }
   ],
   "source": [
    "#L1 Regularization\n",
    "err1 = [[], [], []]\n",
    "acc1 = [[], [], []]\n",
    "best_lamda = 0\n",
    "for l in lamda:\n",
    "    err = [[], [], []]\n",
    "    acc = [[], [], []]\n",
    "\n",
    "    lr = 0.0001\n",
    "    w = (np.random.rand(10, 785)-0.5)\n",
    "    w_past = np.zeros((4, 10, 785))\n",
    "    count = 0\n",
    "    past_loss = 0\n",
    "    for i in range(15):\n",
    "        print i\n",
    "        y = softmax(np.dot(trnX,np.transpose(w)))\n",
    "        loss = error(trnY, y, l)\n",
    "        err[0].append(loss)\n",
    "        err[1].append(error(tstY, softmax(np.dot(tstX,np.transpose(w))),l))\n",
    "        err[2].append(error(valY, softmax(np.dot(valX,np.transpose(w))),l))\n",
    "        acc[0].append(accuracy(trnY, y))\n",
    "        acc[1].append(accuracy(tstY, softmax(np.dot(tstX,np.transpose(w)))))\n",
    "        acc[2].append(accuracy(valY, softmax(np.dot(valX,np.transpose(w)))))\n",
    "        if past_loss <= loss and i > 10:\n",
    "            count += 1\n",
    "            w_past[0] = w_past[1]\n",
    "            w_past[1] = w_past[2]\n",
    "            w_past[2] = w_past[3]\n",
    "            w_past[3] = w\n",
    "        elif past_loss > loss and i > 10:\n",
    "            count = 0\n",
    "            past_loss = -1\n",
    "        if count > 3 and i > 10:\n",
    "            break\n",
    "        grad = np.dot(np.transpose(trnY-y), trnX)\n",
    "        # L2\n",
    "        grad += 2*l*w\n",
    "        # L1\n",
    "#         grad += l*np.sign(w)\n",
    "        w = w + lr*grad\n",
    "        \n",
    "    w_f = w_past[0]\n",
    "    if acc[2][-3] > max_acc:\n",
    "        print \"Here\"\n",
    "        best_lamda = l\n",
    "        max_acc = acc[2][-3]\n",
    "        w_best = w_f\n",
    "        err1 = err\n",
    "        acc1 = acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[5.3119500861820343, 3.3804990857645625, 4.104373228914481, 4.1515825137415883, 4.4396968682148188, 3.4827871756798072, 3.4514700029101077, 3.3962002513092795, 1.8987882023097387, 1.3543028238182973, 1.6595367396165179, 1.009117405318795, 0.79743576635710101, 0.87735733535432514, 0.82705919212242551], [5.054156128210666, 3.6172382381161383, 4.1581445236137506, 4.2251396437066058, 4.558078630915058, 3.6884623701933776, 3.5931057353756639, 3.5541618549606797, 1.9020490335047795, 1.5802984279152894, 1.6907416696211222, 1.1270368699767708, 0.93935864253654722, 0.99971985069072478, 0.99700947426458519], [5.3214016575579066, 3.3636464067051173, 4.0504263169182959, 4.1571663062578752, 4.3615055475570017, 3.6117557633925093, 3.6136480411549163, 3.3582101810024492, 1.9755495241644221, 1.370567790460345, 1.6997031055287541, 1.0030633430413924, 0.85942673054938035, 0.85662969360504804, 0.86791247665350046]]\n",
      "0.0001\n"
     ]
    }
   ],
   "source": [
    "print err1\n",
    "print best_lamda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final testing error =  24.3712322932\n",
      "Final training error =  24.2647709102\n",
      "Final validation error =  24.3049424769\n"
     ]
    }
   ],
   "source": [
    "print \"Final testing error = \", err1[1][-3]\n",
    "print \"Final training error = \", err1[0][-3]\n",
    "print \"Final validation error = \", err1[2][-3]\n",
    "\n",
    "plt.plot([x for x in range(len(err1[0]))], err1[0], label = \"train\")\n",
    "plt.plot([x for x in range(len(err1[1]))], err1[1], label = \"test\")\n",
    "plt.plot([x for x in range(len(err1[2]))], err1[2], label = \"validation\")\n",
    "plt.xlabel(\"Iterations\")\n",
    "plt.ylabel(\"Entropy\")\n",
    "plt.legend(loc='upper right', shadow=True)\n",
    "plt.show()\n",
    "\n",
    "plt.plot([x for x in range(len(acc1[0]))], acc1[0], label = \"train\")\n",
    "plt.plot([x for x in range(len(acc1[1]))], acc1[1], label = \"test\")\n",
    "plt.plot([x for x in range(len(acc1[2]))], acc1[2], label = \"validation\")\n",
    "plt.xlabel(\"Iterations\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.legend(loc='lower right', shadow=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final testing error =  1.20497729043\n",
      "Final training error =  1.04449194056\n",
      "Final validation error =  1.10689338668\n"
     ]
    }
   ],
   "source": [
    "w_f = w_past[0]\n",
    "print \"Final testing error = \", err[1][-3]\n",
    "print \"Final training error = \", err[0][-3]\n",
    "print \"Final validation error = \", err[2][-3]\n",
    "\n",
    "plt.plot([x for x in range(len(err[0]))], err[0], label = \"train\")\n",
    "plt.plot([x for x in range(len(err[1]))], err[1], label = \"test\")\n",
    "plt.plot([x for x in range(len(err[2]))], err[2], label = \"validation\")\n",
    "plt.xlabel(\"Iterations\")\n",
    "plt.ylabel(\"Entropy\")\n",
    "plt.title(\"Using L2 with Lamda = \" + best_lamda)\n",
    "plt.legend(loc='upper right', shadow=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "plt.plot([x for x in range(len(acc[0]))], acc[0], label = \"train\")\n",
    "plt.plot([x for x in range(len(acc[1]))], acc[1], label = \"test\")\n",
    "plt.plot([x for x in range(len(acc[2]))], acc[2], label = \"validation\")\n",
    "plt.xlabel(\"Iterations\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.title(\"Using L2 with Lamda = \" + best_lamda)\n",
    "plt.legend(loc='lower right', shadow=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
